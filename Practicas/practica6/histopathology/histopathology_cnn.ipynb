{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7NPtt80epC2"
      },
      "source": [
        "# Clasificando con Redes Neuronales Convolucionales en Keras.\n",
        "\n",
        "(c) 2022 Frnacisco José Madrid Cuevas <fjmadrid@uco.es>. Universidad de Córdoba. España."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxORhC7Oe0HE"
      },
      "source": [
        "Este cuaderno te permitirá practicar con varios modelos de Red Neuronal Convolucional (**CNN**) para resolver un problema de clasificación.\n",
        "\n",
        "Vamos a utilizar el paquete TensorFlow con la interfaz Keras que permite manejar este tipo de modelos de una forma muy intuitiva.\n",
        "\n",
        "Quizás sería interesante, antes de continuar, que repases en qué consiste una Red Neuronal Convolucional. Estos enlaces [1](https://algobeans.com/2016/03/13/how-do-computers-recognise-handwriting-using-artificial-neural-networks/) y [2](https://en.wikipedia.org/wiki/Convolutional_neural_network) pueden servirte para ello. \n",
        "\n",
        "Vamos a resolver un problema clásico que consiste en clasificar correctamente imágenes de histopatología. En la siguiente figura puedes ver ejemplos de las cuatro categorías que hay en el dataset.\n",
        "\n",
        "![Ejemplo del dataset](https://production-media.paperswithcode.com/datasets/238b8867-fa08-4281-8a53-ca1851132301.png)\n",
        "\n",
        "Nosotros vamos a trabajar con una versión del [dataset original](https://bupt-ai-cz.github.io/HSA-NRL/) con las imágenes escaladas a 128x128.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUXMmr28gzsA"
      },
      "source": [
        "Lo primero será cargar los módulos python necesarios. Usaremos *TensorFlow* con la interfaz *Keras*. Además usaremos *Numpy* para manipular los datos y *Matplotlib* para generar gráficos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBL-oUIU3ARJ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8sSaa5gLBTa"
      },
      "source": [
        "print(\"Tensorflow version \", tf.__version__)\n",
        "print(\"Keras version \",keras.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDaQp-ciL_eQ"
      },
      "source": [
        "## Descargar y preparar el Dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKhD_BxEhJs2"
      },
      "source": [
        "Vamos a descargar y preparar el dataset para poder utilizarlo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LckTYkhCLqKq"
      },
      "source": [
        "%%bash\n",
        "#Descargar el dataset\n",
        "pip install -U gdown\n",
        "gdown -O fsiv_histopathology.zip 17owS_qJ9RPGek32w2-YmFUu2ooNKWrQz\n",
        "pwd\n",
        "unzip fsiv_histopathology.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora vamos a cargar y preparar el dataset. Primero definiremos algunas funciones de utilidad."
      ],
      "metadata": {
        "id": "tTXZ6n9KB52w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(dirname, partition='train'):\n",
        "    \"\"\"\n",
        "    Load the a partition of the histopatology dataset.\n",
        "\n",
        "    Params:\n",
        "\n",
        "    dirname: string\n",
        "       Is the pathname of the datset.\n",
        "\n",
        "    partition: string\n",
        "        Specify which partion to load. Allowed values 'train' or 'test'.\n",
        "\n",
        "    Return:\n",
        "        X: numpy.ndarray\n",
        "            The samples (one per row)\n",
        "        y: numpy.ndarray\n",
        "            The labels (one per row)\n",
        "    \"\"\"\n",
        "    flabels = open(dirname + '/' + partition + '_labels.txt')\n",
        "    lines = flabels.readlines()\n",
        "    X = np.empty((len(lines), 128, 128, 3), 'f')\n",
        "    y = np.empty((len(lines),), 'i')\n",
        "    count = 0\n",
        "    for line in lines:        \n",
        "        data = line.split(' ')        \n",
        "        img_fname = dirname + '/' + data[0]\n",
        "        img = cv2.imread(img_fname, cv2.IMREAD_COLOR).astype('f')/255.0\n",
        "        label = int(data[1])\n",
        "        X[count] = img\n",
        "        y[count] = label\n",
        "        count += 1\n",
        "    return X, y\n",
        "\n",
        "N_CLASSES=4\n",
        "SAMPLE_SHAPE = (128, 128, 3)\n",
        "label_names = [\"Normal\", \"Serrated\", \"Adenocarcinoma\", \"Adenoma\"]\n",
        "X, y = load_dataset('/content/dataset', 'train')"
      ],
      "metadata": {
        "id": "Qiz2OuBlA9XT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PjkgZoKMiTL"
      },
      "source": [
        "Vamos a ver algunas de las imágenes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z45hi39TMmon"
      },
      "source": [
        "fig, axes = plt.subplots(3, 3)\n",
        "for r in range(3):\n",
        "  for c in range(3):\n",
        "    idx = np.random.randint(X.shape[0])    \n",
        "    axes[r,c].axis(False)\n",
        "    axes[r,c].set_title(label_names[y[idx]])\n",
        "    axes[r,c].imshow(X[idx])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOySJPmERACu"
      },
      "source": [
        "### Preprando las etiquetas\n",
        "\n",
        "Tenemos cuatro clases con etiquetas con valores enteros en el rango [0...3]. \n",
        "\n",
        "Nuestra CNN tendrá como capa de salida 4 neuronas asignando una categoría por neurona, siendo la clase predicha la correspondiente a la neurona con mayor respuesta.\n",
        "\n",
        "Para calcular el error cometido en la predicción vamos a transformar las etiquetas enteras a un vector con cuatro valores 0|1 que codifica la etiqueta correspondiente. Por ejemplo la etiqueta 0 se convierte al vector (1,0,0,0), la etiqueta 1 será (0,1,0,0) y así sucesivamente. De esta forma podremos utilizar la función de pérdida `categorical-crossentropy` comparar la salida de la CNN con el valor esperado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYThJykFRu8q"
      },
      "source": [
        "y = keras.utils.to_categorical(y, N_CLASSES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMj8qBEKTWMo"
      },
      "source": [
        "## Creación del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iRGvts-TaSr"
      },
      "source": [
        "Ahora toca crear nuestro modelo CNN para resolver el problema. Vamos a crear varios modelos desde el más simple con un bloque convolucional y una capa oculta totalmente conectada al más complejo con más bloques convolucionales y varias capas ocultas densas.\n",
        "\n",
        "En los tres modelos usaremos en las capas ocultas, la función de activación '*Relu*' sin '*bias*'. La capa de salida tendrá diez neuronas, cada una representará un dígito posible y usaremos la función de activación '*softmax*'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlQo-js1UJo0"
      },
      "source": [
        "def create_model1():  \n",
        "  model = keras.Sequential(      \n",
        "      [keras.Input(shape=SAMPLE_SHAPE, name='Input'),\n",
        "       #TODO: Añade aquí los bloques convolucionales que desees.\n",
        "\n",
        "\n",
        "       #\n",
        "       #Red final densa.\n",
        "       keras.layers.Flatten(),\n",
        "       #TODO: Añade aquí las capas ocultas que desees.\n",
        "\n",
        "       #\n",
        "       keras.layers.Dense(4, activation='softmax', name='Ouput')\n",
        "      ], name= 'Model1')\n",
        "  return model\n",
        "\n",
        "#TODO: crea otros modelos\n",
        "# def create_model2():\n",
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlLTK4e0VzI0"
      },
      "source": [
        "Seleccinonamos el modelo que vamos a entrenar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBzV5OkgV2nA"
      },
      "source": [
        "#Activa/Desactiva comentario para seleccionar el modelo deseado.\n",
        "model = create_model1()\n",
        "#model = create_model2()\n",
        "#model = create_model3()\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1NbowFlN4ej"
      },
      "source": [
        "## Prepación del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_pfQ56NV9Kq"
      },
      "source": [
        "Ahora vamos a preparar el modelo para entrenarlo. Para ello debemos indicar tres cosas principalmente:\n",
        "- **La función de pérdida a utilizar**. La función de pérdida mide la \"distancia\" entre la predicción que da la red para una muestra y el valor de verdad anotado. Cuanto menor sea esa distancia mejor ya que la red predice valores muy próximos a la salidas esperadas (*Ground Truth*). Nosotros vamos a utilizar como métrica la entropía cruzada para N categorias. En este [enlace](https://towardsdatascience.com/cross-entropy-for-classification-d98e7f974451) puedes ver más detalles.\n",
        "- **El algoritmo optimizador**. El optimizador es el algoritmo que va ajustando, de foma iterativa, los parámetros del modelo buscando un mínimo de la función de pérdida. Inicialmente se suele utilizar el algoritmo SGD (Stochastic Gradient Descent). Dependiendo del algoritmo elegido, podremos indicar más parámetros. Nosotros usaremos los parámetros por defecto para el algoritmo SGD.\n",
        "- **Una o varias métricas**. Una métrica mide lo bien que funciona nuestro modelo. Si la red es para clasificar y las clases están balanceadas (es decir, tenemos más o menos las mismas muestras para entrenar por clase) se suele utilizar como métrica la exactitud (*accuracy*). Puedes ver más detalles en este [enlace](https://www.iartificial.net/precision-recall-f1-accuracy-en-clasificacion)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPOVmw3RWav6"
      },
      "source": [
        "#TODO: prueba otro optimizador o cambia parámetros del optimizador como por ejemplo el 'learning rate'.\n",
        "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(),\n",
        "              metrics='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru0w-3cEVwCa"
      },
      "source": [
        "## Entrenamiento del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBcnaeccXHZb"
      },
      "source": [
        "Ahora vamos a realizar el entrenamiento. Vamos a repetir ciclos (épocas) para presentar los datos de entrenamiento por paquetes (*bacth*) para que el optimizador vaya modificando los parámetros del modelo (p. e. los pesos de las conexiones entre capas) buscando un mínimo local de la función de pérdida. Al final de cada época se evaluará el *accuracy* conseguido. Para ello, en cada época se dejará un porción del conjunto de entrenamiento para validar al final.\n",
        "\n",
        "El comportamiento deseable es que el valor de la función de la pérdida para los datos de entrenamiento y validación vayan descendiendo conforme vayan pasando épocas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOzmPDMnXzat"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "N_EPOCH = 50\n",
        "VALIDATION_SIZE = 0.2\n",
        "history = model.fit(X, y, batch_size=BATCH_SIZE, epochs=N_EPOCH,\n",
        "                    validation_split=VALIDATION_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjCULEG_aIvJ"
      },
      "source": [
        "Vamos a mostrar dos gráficos. Uno muestra la evolución de la función de pérdida y el otro la evolución del *accuracy* en las particiones de train/validation.\n",
        "\n",
        "Estos gráficos permiten evaluar el balance \"Sesgo versus Varianza\" (*Bias vs. Variance*) de nuestro modelo.\n",
        "\n",
        "Al principio del entrenamiento, el modelo tendrá un valor de métrica muy pobre, es decir, tendrá un valor alto de sesgo (*underfitting*). Conforme progrese el entrenamiento se irá reduciendo el sesgo. Suele ocurrir, sobre todo cuanto más complejo es el modelo entrenado, que a partir de un punto, la diferencia de la métrica para el conjunto de entrenamiento y para el conjunto de validación comenzará a aumentar, es decir aumentará la varianza. Esto indica que el modelo está *sobre-entrenando* (*overfitting*) y perdiendo poder de generalización, siendo esto una situación no deseable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dv5nBv4raYKc"
      },
      "source": [
        "fig, axes = plt.subplots(2, 1)\n",
        "axes[0].grid(True)\n",
        "axes[0].set_ylabel('Accuracy')\n",
        "axes[0].plot(history.history['accuracy'], 'g-', label='Train')\n",
        "axes[0].plot(history.history['val_accuracy'], 'r-', label='Val.')\n",
        "axes[0].legend()\n",
        "axes[1].grid(True)\n",
        "axes[1].set_ylabel('Loss')\n",
        "axes[1].set_xlabel('Epochs')\n",
        "axes[1].plot(history.history['loss'], 'g-', label='Train')\n",
        "axes[1].plot(history.history['val_loss'], 'r-', label='Val.')\n",
        "axes[1].legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yajJ5aYHjO7D"
      },
      "source": [
        "## Evaluación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhXUHrj0Zisd"
      },
      "source": [
        "Una vez que tenemos nuestro modelo entrenado intentado obtener el mejor balance \"Sesgo/Varianza\", es hora de evaluar el poder de generalización que ha conseguido. Para ello utilizaremos las muestras de la partición para Test. Nótese que estas muestras no han sido vistas por nuestro modelo nunca y por lo tanto, el resultado obtenido permitirá tener una estimación de cómo se comportará el modelo en \"explotación\".\n",
        "\n",
        "También esta evaluación permitirá comparar de forma justa nuestro modelo con otros modelos entrenados, ya que si utilizamos las métricas obtenidas en la fase de entrenamiento para esto, podrímos llegar a conclusiones equivocadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-ivQzMHZmkR"
      },
      "source": [
        "X, y = load_dataset('/content/dataset', 'test')\n",
        "y = keras.utils.to_categorical(y, N_CLASSES)\n",
        "score = model.evaluate(X, y)\n",
        "print(\"Test loss:\", score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}